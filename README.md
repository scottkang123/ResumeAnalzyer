# ResumeAnalyzer

> ğŸš€ A minimal, free-first Resume Analyzer that parses your resume, ingests a job description, scores relevance, highlights gaps, and generates tailored resume variants. Built with Streamlit + local LLMs (Ollama).

<p align="left">
  <img alt="Python" src="https://img.shields.io/badge/Python-3.11-blue">
  <img alt="Streamlit" src="https://img.shields.io/badge/UI-Streamlit-red">
  <img alt="License" src="https://img.shields.io/badge/License-MIT-green">
</p>


## âœ¨ Features (MVP)
- **Upload resume** (PDF/DOCX) â†’ robust text extraction
- **JD ingest** by URL or paste â†’ automatic clean-up
- **Relevance scoring** via sentence-transformer embeddings
- **Skills coverage** (heuristic) using a seed skills list
- **LLM analysis** (via **Ollama**, free/local) for:
  - Actionable edits & gap analysis
  - Tailored bullet rewrites
- **Resume generation** â†’ Markdown and downloadable **.docx**

> Works offline for most steps. LLM features auto-enable if Ollama is running locally.

---

## ğŸ§± Tech Stack
- **UI:** Streamlit
- **Resume Parsing:** `pdfplumber` (PDF), `python-docx` (DOCX)
- **NLP:**
  - Embeddings: `sentence-transformers` (`all-MiniLM-L6-v2`)
  - NER/Cleanup: spaCy `en_core_web_sm` (optional)
  - Zero-shot labels (later): `facebook/bart-large-mnli`
- **Similarity / RAG:** FAISS (or Chroma later)
- **LLM (free/local):** Ollama (`llama3.1:8b` or `mistral`)  
- **Prompting:** Direct prompts (LangChain optional)
- **JD Fetch:** `requests` + `BeautifulSoup`
- **Storage:** Filesystem (upgrade to SQLite later)
- **Doc generation:** Markdown + `python-docx` (PDF via WeasyPrint later)

---

## ğŸ“¦ Project Structure

```text
ResumeAnalyzer/
â”œâ”€ app.py # Streamlit app (upload â†’ scrape â†’ analyze â†’ generate)
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ .gitignore
â”œâ”€ .env.example
â”œâ”€ data/
â”‚ â””â”€ skill_dict.json # seed skills list for coverage checks
â”œâ”€ outputs/ # generated resumes
â”‚ â””â”€ .gitkeep
â””â”€ .streamlit/
â””â”€ config.toml
```


## ğŸš€ Quickstart

### 1) Create a clean environment (recommended)
```bash
conda create -n resumeanalyzer python=3.11 -y
conda activate resumeanalyzer
```
### 2) Install Dependencies
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
conda install -y -c conda-forge numpy
```
- installs spaCyâ€™s small English model into your current Python environment so you can do nlp = spacy.load("en_core_web_sm")

### 3) Run LLM and UI
```bash
ollama pull llama3.1:8b
streamlit run app.py
```
- 

## ğŸ” How It Works (MVP Flow)
- Parse resume â†’ PDF/DOCX â†’ raw text â†’ split into bullets
- Fetch/clean JD from URL or pasted text
- Embeddings (all-MiniLM-L6-v2) â†’ relevance score for top bullets
- Skills coverage (simple keyword match using data/skill_dict.json)
- LLM analysis (if Ollama available) â†’ gap list + bullet rewrites
- Tailored resume â†’ Markdown â†’ export .docx and .md

## ğŸ§­ Roadmap / Nice-to-Haves
- Structured parsing of roles/dates/education with spaCy patterns
- Skill taxonomy & fuzzy matching (e.g., O*NET/ESCO)
- Multi-variant generation (ATS-plain / Impact-first / One-page strict)
- Cover letter auto-draft from tailored resume
- Template-aware output (use a provided PDF/DOCX layout)
- RAG for section-to-section alignment (JD â†” resume)
- Overall â€œJD matchâ€ score with weighted skills/experience
- Session/version persistence (SQLite)
- Diff view for bullets + â€œwhy it helpsâ€ tooltips

## ğŸ“š Glossary
- **JD**: Job Description â€” the role posting youâ€™re targeting.
- **ATS**: Applicant Tracking System â€” software that parses and filters resumes.

## ğŸ” Privacy
- Local-first by default. If you later enable external APIs, store keys in .env and donâ€™t commit them.

## ğŸ¤ Contributing
- PRs welcome. Open an issue to discuss significant changes.
